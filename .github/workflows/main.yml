name: MLOps CI

on:
  push:
    branches: ["main"]
  pull_request:

jobs:
  build-train-test:
    runs-on: ubuntu-latest

    env:
      PYTHON_VERSION: "3.11"
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      MLFLOW_S3_ENDPOINT_URL: "http://localhost:9000"
      MLFLOW_TRACKING_URI: "http://localhost:5000"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install dvc[s3] optuna mlflow scikit-learn pandas joblib requests fastapi "uvicorn[standard]"

      # 1) Start MinIO
      - name: Start MinIO
        run: |
          docker run -d --name minio --network host \
            -e MINIO_ROOT_USER=$AWS_ACCESS_KEY_ID \
            -e MINIO_ROOT_PASSWORD=$AWS_SECRET_ACCESS_KEY \
            minio/minio:latest server /data --console-address ":9001"
          # wait until ready
          for i in {1..30}; do
            curl -fsS http://localhost:9000/minio/health/live && break
            sleep 2
          done
          curl -f http://localhost:9000/minio/health/live

      # 2) Create bucket for MLflow artifacts
      - name: Create MinIO bucket (mlflow)
        run: |
          docker run --rm --network host \
          --entrypoint mc \
          minio/mc:latest alias set local http://localhost:9000 $AWS_ACCESS_KEY_ID $AWS_SECRET_ACCESS_KEY

          docker run --rm --network host \
          --entrypoint mc \
          minio/mc:latest mb --ignore-existing local/mlflow

          echo "Bucket mlflow OK"


      # 3) Start MLflow server
      - name: Start MLflow
        run: |
          docker run -d --name mlflow --network host \
            -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \
            -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
            -e MLFLOW_S3_ENDPOINT_URL=$MLFLOW_S3_ENDPOINT_URL \
            ghcr.io/mlflow/mlflow:latest \
            mlflow server \
              --host 0.0.0.0 --port 5000 \
              --backend-store-uri sqlite:////tmp/mlflow.db \
              --default-artifact-root s3://mlflow
          # wait until ready
          for i in {1..30}; do
            curl -fsS http://localhost:5000 && break
            sleep 2
          done
          curl -f http://localhost:5000

      - name: DVC pull data (if remote configured)
        run: |
          dvc --version
          dvc pull || echo "No DVC remote / nothing to pull"

      - name: Train baseline + export models
        run: |
          python src/serving/export_models.py

      - name: Start API (uvicorn) & test /health
        run: |
          export MODEL_PATH=models/production/model.joblib
          nohup uvicorn src.serving.app:app --host 0.0.0.0 --port 8000 >/tmp/api.log 2>&1 &
          sleep 3
          curl -f http://localhost:8000/health
          tail -n 80 /tmp/api.log
          pkill -f "uvicorn src.serving.app:app" || true

      - name: Build Docker image (serving)
        run: |
          docker build -f docker/serving.Dockerfile -t breastcancer-api:ci .

      - name: Run container & test /health
        run: |
          docker run -d --name api -p 8000:8000 breastcancer-api:ci
          sleep 3
          curl -f http://localhost:8000/health
          docker logs api --tail=80

      - name: Cleanup
        if: always()
        run: |
          docker logs minio --tail=50 || true
          docker logs mlflow --tail=50 || true
          docker rm -f api mlflow minio || true
